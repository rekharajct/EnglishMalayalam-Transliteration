{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!pip install wandb\n",
        "!pip install torchtext==0.6.0\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "zrEnW3OJvH0Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7sSeDxSLu5n3"
      },
      "outputs": [],
      "source": [
        "import wandb\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import random\n",
        "from tqdm import tqdm\n",
        "from torchtext.legacy.data import TabularDataset\n",
        "from torchtext.legacy.data import Field, BucketIterator\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "import sys\n",
        "dir_path = \"/content/drive/MyDrive/DL assignment/test16/\"\n",
        "sys.path.append(dir_path)\n",
        "from torchtext.data import TabularDataset\n",
        "from torchtext.data import Field, BucketIterator\n",
        "\n",
        "\n",
        "data_path = dir_path +\"mal/\"\n",
        "train_path = data_path + \"mal_train.csv\"\n",
        "test_path = data_path + \"mal_test.csv\"\n",
        "valid_path = data_path + \"mal_valid.csv\"\n",
        "sys.path.append(data_path)\n",
        "\n",
        "\n",
        "train_file = data_path +\"mal/mal_train.csv\"\n",
        "valid_file = data_path +\"mal/mal_valid.csv\"\n",
        "test_file  = data_path + \"mal/mal_test.csv\"\n",
        "\n",
        "\n",
        "\n",
        "correct_path = dir_path + \"correct.csv\"\n",
        "incorrect_path = dir_path + \"incorrect.csv\"\n",
        "\n",
        "\n",
        "def tokenize(word):\n",
        "    return list(word)\n",
        "\n",
        "\n",
        "def get_datasets(device, batch_size=2):\n",
        "    \n",
        "\n",
        "    # Create the pytext's Field\n",
        "    source_field = Field(tokenize=tokenize,\n",
        "                    init_token='<sos>', \n",
        "                    eos_token='<eos>', \n",
        "                    pad_token=\"<pad>\",\n",
        "                    unk_token=\"<unk>\",\n",
        "                    lower=False)\n",
        "    target_field = Field(tokenize=tokenize,\n",
        "                    init_token='<sos>',\n",
        "                    eos_token='<eos>',\n",
        "                    pad_token=\"<pad>\",\n",
        "                    unk_token=\"<unk>\",\n",
        "                    )\n",
        "\n",
        "    # Splits the data in Train, Test and Validation data\n",
        "    train_set, valid_set, test_set = TabularDataset.splits(\n",
        "        path=\"\",\n",
        "        train=train_path,\n",
        "        validation=valid_path,\n",
        "        test=test_path,\n",
        "        format=\"csv\",\n",
        "        csv_reader_params={\"delimiter\": \",\", \"skipinitialspace\": True},\n",
        "        fields=[(\"src\", source_field), (\"trg\", target_field)],)\n",
        "\n",
        "    # Build the vocabulary for both the language\n",
        "    source_field.build_vocab(train_set, min_freq=1)\n",
        "    target_field.build_vocab(train_set, min_freq=1)\n",
        "\n",
        "    # Create the Iterator using builtin Bucketing\n",
        "    train_iterator, valid_iterator, test_iterator = BucketIterator.splits((train_set,\\\n",
        "                                                valid_set, test_set),\n",
        "                                                batch_size=batch_size,\n",
        "                                                sort_within_batch=True,\n",
        "                                                sort_key=lambda x: len(x.src),\n",
        "                                                device=device)\n",
        "    return train_iterator, valid_iterator, test_iterator, source_field, target_field\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yq3c5PIeu5n5"
      },
      "outputs": [],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HdW_i06ou5n7"
      },
      "outputs": [],
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self, input_dim, emb_dim, hidden_dim, dropout):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.embedding = nn.Embedding(input_dim, emb_dim)\n",
        "        \n",
        "        self.rnn = nn.GRU(emb_dim, hidden_dim, bidirectional = True)\n",
        "        \n",
        "        self.fc = nn.Linear(hidden_dim * 2, hidden_dim)\n",
        "        \n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "    def forward(self, src):\n",
        "        \n",
        "        #src = [src len, batch size]\n",
        "        \n",
        "        embedded = self.dropout(self.embedding(src))\n",
        "        \n",
        "        #embedded = [src len, batch size, emb dim]\n",
        "        \n",
        "        outputs, hidden = self.rnn(embedded)\n",
        "                \n",
        "        hidden = torch.tanh(self.fc(torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim = 1)))\n",
        "                \n",
        "        return outputs, hidden"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yCFoJJxBu5n8"
      },
      "outputs": [],
      "source": [
        "class Attention(nn.Module):\n",
        "    def __init__(self, hidden_dim):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.U = nn.Linear((hidden_dim * 2) + hidden_dim, hidden_dim)\n",
        "        self.V = nn.Linear(hidden_dim, 1, bias = False)\n",
        "        \n",
        "    def forward(self, hidden, encoder_outs):\n",
        "        \n",
        "        \n",
        "        batch_size = encoder_outs.shape[1]\n",
        "        src_len = encoder_outs.shape[0]\n",
        "        \n",
        "        \n",
        "        hidden = hidden.unsqueeze(1).repeat(1, src_len, 1)\n",
        "        \n",
        "        encoder_outs = encoder_outs.permute(1, 0, 2)    \n",
        "        \n",
        "        \n",
        "        energy = torch.tanh(self.U(torch.cat((hidden, encoder_outs), dim = 2))) \n",
        "        \n",
        "        att_score = self.V(energy).squeeze(2)\n",
        "        att_weights = torch.softmax(att_score, dim=1)\n",
        "        \n",
        "        #attention= [batch size, src len]\n",
        "        \n",
        "        return att_weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QISDuRrXu5n-"
      },
      "outputs": [],
      "source": [
        "class Decoder(nn.Module):\n",
        "    def __init__(self, output_dim, emb_dim, hidden_dim, dropout, attention):\n",
        "        super().__init__()\n",
        "\n",
        "        self.output_dim = output_dim\n",
        "        self.attention = attention\n",
        "        \n",
        "        self.embedding = nn.Embedding(output_dim, emb_dim)\n",
        "        \n",
        "        self.rnn = nn.GRU((hidden_dim * 2) + emb_dim, hidden_dim)\n",
        "        \n",
        "        self.fc_out = nn.Linear((hidden_dim * 2) + hidden_dim + emb_dim, output_dim)\n",
        "        \n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "    def forward(self, input, hidden, encoder_outs):\n",
        "             \n",
        "        #input = [batch size]\n",
        "        #hidden = [batch size, dec hid dim]\n",
        "        #encoder_outputs = [src len, batch size, enc hid dim * 2]\n",
        "        \n",
        "        input = input.unsqueeze(0)\n",
        "        \n",
        "        #input = [1, batch size]\n",
        "        \n",
        "        embedded = self.dropout(self.embedding(input))\n",
        "        \n",
        "        #embedded = [1, batch size, emb dim]\n",
        "        \n",
        "        att_wts = self.attention(hidden, encoder_outs)\n",
        "                \n",
        "        #a = [batch size, src len]\n",
        "        \n",
        "        att_wts = att_wts.unsqueeze(1)\n",
        "        \n",
        "        #a = [batch size, 1, src len]\n",
        "        \n",
        "        encoder_outs = encoder_outs.permute(1, 0, 2)\n",
        "        \n",
        "        #encoder_outputs = [batch size, src len, enc hid dim * 2]\n",
        "        \n",
        "        weighted_embed = torch.bmm(att_wts, encoder_outs)\n",
        "        \n",
        "        #weighted = [batch size, 1, enc hid dim * 2]\n",
        "        \n",
        "        weighted_embed = weighted_embed.permute(1, 0, 2)\n",
        "        \n",
        "        #weighted = [1, batch size, enc hid dim * 2]\n",
        "        \n",
        "        rnn_input = torch.cat((embedded, weighted_embed), dim = 2)\n",
        "        \n",
        "        #rnn_input = [1, batch size, (enc hid dim * 2) + emb dim]\n",
        "            \n",
        "        output, hidden = self.rnn(rnn_input, hidden.unsqueeze(0))\n",
        "        \n",
        "        \n",
        "        embedded = embedded.squeeze(0)\n",
        "        output = output.squeeze(0)\n",
        "        weighted_embed = weighted_embed.squeeze(0)\n",
        "        \n",
        "        prediction = self.fc_out(torch.cat((output, weighted_embed, embedded), dim = 1))\n",
        "        \n",
        "        #prediction = [batch size, output dim]\n",
        "        \n",
        "        return prediction, hidden.squeeze(0), att_wts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1CnRjOo3u5n-"
      },
      "outputs": [],
      "source": [
        "class Seq2Seq(nn.Module):\n",
        "    def __init__(self, encoder, decoder, device):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "        self.device = device\n",
        "        \n",
        "    def forward(self, src, trg, teacher_forcing_ratio=0.5):\n",
        "        \n",
        "        #src = [src len, batch size]\n",
        "        #trg = [trg len, batch size]\n",
        "        #teacher_forcing_ratio is probability to use teacher forcing\n",
        "        #e.g. if teacher_forcing_ratio is 0.75 we use teacher forcing 75% of the time\n",
        "        \n",
        "        batch_size = src.shape[1]\n",
        "        trg_len = trg.shape[0]\n",
        "        trg_vocab_size = self.decoder.output_dim\n",
        "        \n",
        "        #tensor to store decoder outputs\n",
        "        outputs = torch.zeros(trg_len, batch_size, trg_vocab_size).to(self.device)\n",
        "        \n",
        "        #encoder_outputs is all hidden states of the input sequence, back and forwards\n",
        "        #hidden is the final forward and backward hidden states, passed through a linear layer\n",
        "        encoder_outs, hidden = self.encoder(src)\n",
        "                \n",
        "        #first input to the decoder is the <sos> tokens\n",
        "        input = trg[0,:]\n",
        "        \n",
        "        for t in range(1, trg_len):\n",
        "            \n",
        "            #insert input token embedding, previous hidden state and all encoder hidden states\n",
        "            #receive output tensor (predictions) and new hidden state\n",
        "            output, hidden, att_wts = self.decoder(input, hidden, encoder_outs)\n",
        "            \n",
        "            #place predictions in a tensor holding predictions for each token\n",
        "            outputs[t] = output\n",
        "            \n",
        "            #decide if we are going to use teacher forcing or not\n",
        "            teacher_force = random.random() < teacher_forcing_ratio\n",
        "            \n",
        "            #get the highest predicted token from our predictions\n",
        "            top1 = output.argmax(1) \n",
        "            \n",
        "            #if teacher forcing, use actual next token as next input\n",
        "            #if not, use predicted token\n",
        "            input = trg[t] if teacher_force else top1\n",
        "\n",
        "        return outputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DRHJ3tnMu5n_"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n9kZwFodu5n_"
      },
      "outputs": [],
      "source": [
        "TARGET_PAD_IDX = target.vocab.stoi[target.pad_token]\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=TARGET_PAD_IDX)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8etvLNzpu5oA"
      },
      "outputs": [],
      "source": [
        "def train(model, iterator, optimizer, criterion, clip,teacher_forcing_ratio):\n",
        "    \n",
        "    model.train()\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    \n",
        "    for i, batch in enumerate(iterator):\n",
        "        \n",
        "        src = batch.src\n",
        "        trg = batch.trg\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        output = model(src, trg)\n",
        "        \n",
        "        #trg = [trg len, batch size]\n",
        "        #output = [trg len, batch size, output dim]\n",
        "        \n",
        "        output_dim = output.shape[-1]\n",
        "        \n",
        "        output = output[1:].view(-1, output_dim)\n",
        "        trg = trg[1:].view(-1)\n",
        "        \n",
        "        #trg = [(trg len - 1) * batch size]\n",
        "        #output = [(trg len - 1) * batch size, output dim]\n",
        "        \n",
        "        loss = criterion(output, trg)\n",
        "        \n",
        "        loss.backward()\n",
        "        \n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
        "        \n",
        "        optimizer.step()\n",
        "        \n",
        "        epoch_loss += loss.item()\n",
        "        \n",
        "    return epoch_loss / len(iterator)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nKgYVha_u5oB"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Aa2FVfgbu5oB"
      },
      "outputs": [],
      "source": [
        "def evaluate(model, iterator, criterion):\n",
        "    \n",
        "    model.eval()\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    \n",
        "    with torch.no_grad():\n",
        "    \n",
        "        for i, batch in enumerate(iterator):\n",
        "\n",
        "            src = batch.src\n",
        "            trg = batch.trg\n",
        "\n",
        "            output = model(src, trg, 0) #turn off teacher forcing\n",
        "\n",
        "            #trg = [trg len, batch size]\n",
        "            #output = [trg len, batch size, output dim]\n",
        "\n",
        "            output_dim = output.shape[-1]\n",
        "            \n",
        "            output = output[1:].view(-1, output_dim)\n",
        "            trg = trg[1:].view(-1)\n",
        "\n",
        "            #trg = [(trg len - 1) * batch size]\n",
        "            \n",
        "            #output = [(trg len - 1) * batch size, output dim]\n",
        "            \n",
        "            loss = criterion(output, trg)\n",
        "            \n",
        "            epoch_loss += loss.item()\n",
        "        \n",
        "    return epoch_loss / len(iterator)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iSGy8mBSu5oB"
      },
      "outputs": [],
      "source": [
        "def predict_word(device, model, source, target, src, trg):\n",
        "    #print(src, trg)\n",
        "    src_tensor = source.process([src]).to(device)\n",
        "    trg_tensor = target.process([trg]).to(device)\n",
        "    #print(src_tensor)\n",
        "  \n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "      outputs = model(src_tensor, trg_tensor, teacher_forcing_ratio=0)\n",
        "    output_ids = outputs[1:].squeeze(1).argmax(1)\n",
        "    output_tokens = [target.vocab.itos[idx] for idx in output_ids]\n",
        "    return output_tokens\n",
        "    \n",
        "\n",
        "def predict(device, model, iterator, source, target, testfile, correct_path, incorrect_path, save_pred):\n",
        "    src_words_correct = []\n",
        "    trg_words_correct = []\n",
        "    pred_words_correct = []\n",
        "    src_words_incorrect = []\n",
        "    trg_words_incorrect = []\n",
        "    pred_words_incorrect = []\n",
        "    src_vocab = source.vocab\n",
        "    trg_vocab = target.vocab\n",
        "    test_data = pd.read_csv(testfile,sep=\",\")\n",
        "    src = test_data.iloc[:,0]\n",
        "    trg = test_data.iloc[:,1]\n",
        "    num_predictions = len(src)\n",
        "    correct_predictions = 0\n",
        "    for s, t  in zip(src, trg):\n",
        "        pred_word = predict_word(device, model,source, target, s, t)\n",
        "        #print(\"pred_\",pred_word)\n",
        "        src_list = tokenize(s)\n",
        "        trg_list = tokenize(t)\n",
        "        pred_list = [item for item in pred_word if '<eos>' not in item and '<sos>' not in item]\n",
        "        \n",
        "        src_str = \"\".join(src_list)\n",
        "        trg_str = \"\".join(trg_list)\n",
        "        pred_str = \"\".join(pred_list)\n",
        "        if trg_list == pred_list:\n",
        "            src_words_correct.append(s)\n",
        "            trg_words_correct.append(t)\n",
        "            pred_words_correct.append(pred_str)\n",
        "            correct_predictions+=1\n",
        "        else:\n",
        "            src_words_incorrect.append(s)\n",
        "            trg_words_incorrect.append(t)\n",
        "            pred_words_incorrect.append(pred_str)\n",
        "    accuracy = correct_predictions*100.0/num_predictions\n",
        "    if save_pred:\n",
        "      df_correct = pd.DataFrame({\"source\":src_words_correct, \"target\":trg_words_correct,\\\n",
        "                                    \"prediction\": pred_words_correct})\n",
        "      df_incorrect = pd.DataFrame({\"source\":src_words_incorrect, \"target\":trg_words_incorrect,\\\n",
        "                                    \"prediction\": pred_words_incorrect})\n",
        "      df_correct.to_csv(correct_path, index=False)\n",
        "      df_incorrect.to_csv(incorrect_path, index=False)\n",
        "      \n",
        "    return accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FDztP4Kpu5oC"
      },
      "outputs": [],
      "source": [
        "#Hyperparameters\n",
        "lr = 0.001\n",
        "batch_size =16\n",
        "epochs = 20\n",
        "clip = 1\n",
        "rnn_type = \"GRU\"\n",
        "bidirectional = True\n",
        "teacher_forcing_ratio = 0.5\n",
        "optimizer = \"adam\"\n",
        "enc_embed_dim = 256\n",
        "dec_embed_dim = 256\n",
        "hidden_dim = 512\n",
        "num_layers = 1\n",
        "dropout_prob = 0.5\n",
        "clip = 1\n",
        "\n",
        "\n",
        "save_pred = True\n",
        "if_test = True\n",
        "\n",
        "\n",
        "config_defaults = { \"lr\": lr,                \n",
        "        \"batch_size\": batch_size,\n",
        "        \"epochs\": epochs,\n",
        "        \"clip\": clip,\n",
        "        \"rnn_type\" : rnn_type,\n",
        "        \"enc_embed_dim\":enc_embed_dim,\n",
        "        \"hidden_dim\": hidden_dim,\n",
        "        \"dec_embed_dim\":dec_embed_dim,\n",
        "        \"dropout_prob\": dropout_prob,\n",
        "        \"teacher_forcing_ratio\" :teacher_forcing_ratio,\n",
        "        \"optimizer\": optimizer\n",
        "    }\n",
        "\n",
        "\n",
        "sweep_config = {\n",
        "        'method': 'bayes',\n",
        "        'metric': {\n",
        "            'name': 'validation loss',\n",
        "            'goal': 'minimize'\n",
        "        },\n",
        "        'parameters':{\n",
        "            \"lr\":{\n",
        "              \"values\":[0.01, 0.001, 0.0001]\n",
        "              },\n",
        "            \"batch_size\":{\n",
        "              \"values\":[16,64,128, 256]\n",
        "              },\n",
        "            \"epochs\":{\n",
        "              \"values\":[50]\n",
        "              },\n",
        "            \"clip\":{\n",
        "            \"values\":[0.5,1]\n",
        "            },\n",
        "\n",
        "            \"rnn_type\":{\n",
        "              \"values\":[\"GRU\"]\n",
        "              },\n",
        "\n",
        "            \"enc_embed_dim\":{\n",
        "              \"values\":[64, 128, 256]\n",
        "              },\n",
        "            \"dec_embed_dim\":{\n",
        "              \"values\":[32, 64,128, 256, 512]\n",
        "              },\n",
        "              \n",
        "\n",
        "            \"hidden_dim\":{\n",
        "              \"values\":[128, 256,512,1024 ]\n",
        "              },\n",
        "                      \n",
        "            \n",
        "            \"dropout_prob\":{\n",
        "              \"values\":[0.3, 0.5, 0.7]\n",
        "              },\n",
        "\n",
        "            \"teacher_forcing_ratio\":{\n",
        "                \"values\":[0.3, 0.5, 0.7]\n",
        "            },         \n",
        "\n",
        "            \"optimizer\":{\n",
        "              \"values\":[\"adam\", \"nadam\", \"rmsprop\"]\n",
        "              }\n",
        "      }\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2_WxRrZqu5oD"
      },
      "outputs": [],
      "source": [
        "def init_weights(m):\n",
        "    for name, param in m.named_parameters():\n",
        "        nn.init.uniform_(param.data, -0.08, 0.08)\n",
        "        \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "08aYzOdFu5oD"
      },
      "outputs": [],
      "source": [
        "def create_model_GRU(inp_dim,out_dim, enc_embed_dim,dec_embed_dim, hidden_dim, dropout_prob,\\\n",
        "                 source, target, lr , optm):\n",
        "  attn = Attention(hidden_dim)            \n",
        "  enc = Encoder(inp_dim, enc_embed_dim, hidden_dim,dropout_prob,)\n",
        "  dec = Decoder(out_dim, dec_embed_dim, hidden_dim,  dropout_prob, attn)\n",
        "\n",
        "\n",
        "  model = Seq2Seq(enc, dec, device).to(device)\n",
        "  model.apply(init_weights)\n",
        "  # Define the optimizer\n",
        "  if optm == \"adam\":\n",
        "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "  if optm == \"nadam\":\n",
        "    optimizer = optim.NAdam(model.parameters(), lr=lr)\n",
        "  if optm == \"rmsprop\":\n",
        "    optimizer = optim.RMSprop(model.parameters(), lr=lr)\n",
        "  # CrossEntropyLoss: ignores the padding tokens.\n",
        "  TARGET_PAD_IDX = target.vocab.stoi[target.pad_token]\n",
        "  criterion = nn.CrossEntropyLoss(ignore_index=TARGET_PAD_IDX)\n",
        "\n",
        "  return model, optimizer, criterion\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jR2SjaeSu5oE"
      },
      "outputs": [],
      "source": [
        "def transliterate():\n",
        "  #initalize wandb with default configuaration\n",
        "  wandb.init(config=config_defaults)\n",
        "  #config=wandb.config\n",
        "  config = config_defaults\n",
        "    \n",
        "  \n",
        "  #set wandb run name\n",
        "  wandb.run.name = \"e_{}_lr_{}_bs_{}_c_{}_rnn_{}_eed_{}_ded_{}_hd_{}_dr_{}_tf_{}_o{}\".format(\n",
        "  config[\"epochs\"],\n",
        "  config[\"lr\"],\n",
        "  config[\"batch_size\"],\n",
        "  config[\"clip\"],\n",
        "  config[\"rnn_type\"],\n",
        "  config[\"enc_embed_dim\"],\n",
        "  config[\"dec_embed_dim\"],\n",
        "  config[\"hidden_dim\"],\n",
        "  config[\"dropout_prob\"],\n",
        "  config[\"teacher_forcing_ratio\"],\n",
        "  config[\"optimizer\"]\n",
        "  ) \n",
        "\n",
        "  \n",
        "    \n",
        "\n",
        "    \n",
        "  train_iterator, valid_iterator, test_iterator, source, target = get_datasets(device, config[\"batch_size\"])\n",
        "  inp_dim = len(source.vocab)\n",
        "  out_dim = len(target.vocab)\n",
        " \n",
        "  if config[\"rnn_type\"]==\"GRU\":\n",
        "    model, optimizer, criterion = create_model_GRU(inp_dim,out_dim, config[\"enc_embed_dim\"],\\\n",
        "          config[\"dec_embed_dim\"], config[\"hidden_dim\"], config[\"dropout_prob\"],\\\n",
        "          source, target, config[\"lr\"],config[\"optimizer\"])\n",
        "  \n",
        "  for epoch in range(config[\"epochs\"]):\n",
        "  \n",
        "      \n",
        "      \n",
        "      train_loss = train(model, train_iterator, optimizer, criterion, config[\"clip\"], \\\n",
        "                         config[\"teacher_forcing_ratio\"])\n",
        "      valid_loss = evaluate(model, valid_iterator, criterion)\n",
        "      \n",
        "      print(f'Epoch: {epoch}  Train Loss: {train_loss:.3f}  Val. Loss: {valid_loss:.3f} ')\n",
        "      wandb.log({'train_loss':train_loss, 'valid_loss': valid_loss})\n",
        "  \n",
        "\n",
        "  \n",
        "  test_loss = evaluate(model, test_iterator, criterion)\n",
        "  valid_acc = predict(device, model, valid_iterator, source, target, valid_path, correct_path,\\\n",
        "                          incorrect_path, save_pred)\n",
        "  test_acc = predict(device, model, test_iterator, source, target, test_path, correct_path,\\\n",
        "                          incorrect_path, save_pred)\n",
        "  print(f' Test Loss: {test_loss:.3f}, valid acc:{valid_acc:.3f} testacc:{test_acc}' )\n",
        "  wandb.log({'valid_accuracy':valid_acc, 'test_accuracy':test_acc, 'test_loss': test_loss})\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MCUdv1Uju5oE",
        "outputId": "6e3318eb-f524-46b4-c1af-841bfb483549"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 0  Train Loss: 3.146  Val. Loss: 3.019 \n",
            "Epoch: 1  Train Loss: 3.053  Val. Loss: 2.793 \n",
            "Epoch: 2  Train Loss: 2.790  Val. Loss: 2.567 \n",
            "Epoch: 3  Train Loss: 2.516  Val. Loss: 2.308 \n",
            "Epoch: 4  Train Loss: 2.222  Val. Loss: 2.165 \n",
            "Epoch: 5  Train Loss: 2.208  Val. Loss: 2.323 \n",
            "Epoch: 6  Train Loss: 2.475  Val. Loss: 1.843 \n",
            "Epoch: 7  Train Loss: 1.871  Val. Loss: 1.851 \n",
            "Epoch: 8  Train Loss: 1.910  Val. Loss: 1.638 \n",
            "Epoch: 9  Train Loss: 1.634  Val. Loss: 1.453 \n",
            "Epoch: 10  Train Loss: 1.493  Val. Loss: 1.458 \n",
            "Epoch: 11  Train Loss: 1.356  Val. Loss: 1.326 \n",
            "Epoch: 12  Train Loss: 1.318  Val. Loss: 1.294 \n",
            "Epoch: 13  Train Loss: 1.264  Val. Loss: 1.309 \n",
            "Epoch: 14  Train Loss: 1.341  Val. Loss: 1.110 \n",
            "Epoch: 15  Train Loss: 0.971  Val. Loss: 0.978 \n",
            "Epoch: 16  Train Loss: 0.847  Val. Loss: 0.981 \n",
            "Epoch: 17  Train Loss: 0.895  Val. Loss: 0.993 \n",
            "Epoch: 18  Train Loss: 0.768  Val. Loss: 0.878 \n",
            "Epoch: 19  Train Loss: 0.816  Val. Loss: 0.972 \n",
            " Test Loss: 0.972, valid acc:31.579 testacc:31.57894736842105\n"
          ]
        }
      ],
      "source": [
        "#transliterate()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gAi7ATo4u5oF",
        "outputId": "24cab920-215e-4a33-a841-e5187f818f93"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Create sweep with ID: udvlfzlk\n",
            "Sweep URL: https://wandb.ai/deep-learning-assignment/SeqToSeQ_att/sweeps/udvlfzlk\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: u3rl6swe with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tclip: 1\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdec_embed_dim: 256\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout_prob: 0.3\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tenc_embed_dim: 64\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 50\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_dim: 512\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.001\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: rmsprop\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \trnn_type: GRU\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tteacher_forcing_ratio: 0.7\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 0  Train Loss: 3.264  Val. Loss: 2.972 \n",
            "Epoch: 1  Train Loss: 2.953  Val. Loss: 2.750 \n",
            "Epoch: 2  Train Loss: 2.777  Val. Loss: 2.577 \n",
            "Epoch: 3  Train Loss: 2.574  Val. Loss: 2.316 \n",
            "Epoch: 4  Train Loss: 2.310  Val. Loss: 2.217 \n",
            "Epoch: 5  Train Loss: 2.110  Val. Loss: 2.148 \n",
            "Epoch: 6  Train Loss: 1.999  Val. Loss: 1.954 \n",
            "Epoch: 7  Train Loss: 1.867  Val. Loss: 1.732 \n",
            "Epoch: 8  Train Loss: 1.783  Val. Loss: 1.573 \n",
            "Epoch: 9  Train Loss: 1.666  Val. Loss: 1.521 \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Ctrl + C detected. Stopping sweep.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 10  Train Loss: 1.443  Val. Loss: 1.369 \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 11  Train Loss: 1.339  Val. Loss: 1.390 \n",
            "Epoch: 12  Train Loss: 1.366  Val. Loss: 1.396 \n",
            "Epoch: 13  Train Loss: 1.240  Val. Loss: 1.165 \n",
            "Epoch: 14  Train Loss: 1.050  Val. Loss: 0.944 \n",
            "Epoch: 15  Train Loss: 1.011  Val. Loss: 1.042 \n",
            "Epoch: 16  Train Loss: 0.921  Val. Loss: 0.918 \n",
            "Epoch: 17  Train Loss: 0.801  Val. Loss: 0.866 \n",
            "Epoch: 18  Train Loss: 0.667  Val. Loss: 1.041 \n",
            "Epoch: 19  Train Loss: 0.813  Val. Loss: 0.998 \n",
            " Test Loss: 0.998, valid acc:31.579 testacc:31.57894736842105\n"
          ]
        }
      ],
      "source": [
        "\n",
        "#set project name\n",
        "project_name = \"bestseq1\"\n",
        "#set entity name\n",
        "entity_name = \"deep-learning-assignment\"\n",
        "#entity_name = \"dlresearchdl\"\n",
        "# Initialize sweep by passing in config.\n",
        "sweep_id = wandb.sweep(sweep_config,project=project_name, entity=entity_name)\n",
        "wandb.agent(sweep_id, function = transliterate, count=1) #for starting the job\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8ZNGIv8Iu5oG"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R6u_mrmsu5oG"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aJH8qHx0u5oH"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    },
    "orig_nbformat": 4,
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}